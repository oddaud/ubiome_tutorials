{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Getting Started\n",
    "Download uBiome fastq reads as .zip files into one directory names 'ubiomeSamples' on your local computer. \n",
    "\n",
    "Copy this local directory to your qiime community server, using scp. For example edit the following code: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##DO NOT evaluate this cell! This command must be edited, copied, and run from your LOCAL terminal. \n",
    "scp -i [location of your key] -r [path to the local folder]/ubiomeSamples ubuntu@[public DNS]:/home/ubuntu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also need to create a mapping file for your samples. Qiimes mapping file contains information about the sample IDs, barcodes, primers, and information about the samples that you chose to include (for example, sampling location, date, and species). These files must be in a very particular format, read about it [here](http://qiime.org/documentation/file_formats.html). For an example file, look [here](https://docs.google.com/spreadsheets/u/1/d/1FXHtTmvw1gM4oUMbRdwQIEOZJlhFGeMNUvZmuEFqpps/pubhtml?gid=0&single=true).\n",
    "\n",
    "Ubiome data is slightly different than most data that is inputted into qiime because it has already been demultiplexed and the primers trimmed, which means those two columns will remain blank in your mapping file. However, they still must be present. \n",
    "\n",
    "If you have not already, generate a mapping file for your samples. This is most easily done in an excel spreadsheet, but the file must be saved as a tab seperated values (.tsv). Transfer this file to the AWS community server, and place it in the ubiomeSamples folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##DO NOT evaluate this cell! This command must be edited, copied, and run from yout LOCAL terminal. \n",
    "scp -i [location of your key] [path to your map.tsv] ubuntu@[public DNS]:/home/ubuntu/ubiomeSamples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now test to see if your mapping file is formated correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from os import chdir\n",
    "from IPython.display import FileLinks, FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#enter ubiomeSamples directory\n",
    "chdir('ubiomeSamples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/ubiomeSamples\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors and/or warnings detected in mapping file.  Please check the log and html file for details.\r\n"
     ]
    }
   ],
   "source": [
    "!validate_mapping_file.py -o vmf-map/ -m ../map.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Path (<tt>vmf-map-bad</tt>) doesn't exist. It may still be in the process of being generated, or you may have the incorrect path."
      ],
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLinks('vmf-map-bad/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have all your samples, as .zip files, in one folder on the qiime server alongside your mapping file (used later on). \n",
    "\n",
    "Change directories, unzip those files, and delete the original .zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ssr_87975.zip\n",
      "  inflating: ssr_87975__R1__L003.fastq.gz  \n",
      "  inflating: ssr_87975__R1__L002.fastq.gz  \n",
      "  inflating: ssr_87975__R1__L004.fastq.gz  \n",
      "  inflating: ssr_87975__R2__L004.fastq.gz  \n",
      "  inflating: ssr_87975__R1__L001.fastq.gz  \n",
      "  inflating: ssr_87975__R2__L002.fastq.gz  \n",
      "  inflating: ssr_87975__R2__L001.fastq.gz  \n",
      "  inflating: ssr_87975__R2__L003.fastq.gz  \n",
      "\n",
      "Archive:  ssr_87372.zip\n",
      "  inflating: ssr_87372__R1__L002.fastq.gz  \n",
      "  inflating: ssr_87372__R2__L003.fastq.gz  \n",
      "  inflating: ssr_87372__R1__L003.fastq.gz  \n",
      "  inflating: ssr_87372__R2__L002.fastq.gz  \n",
      "  inflating: ssr_87372__R1__L004.fastq.gz  \n",
      "  inflating: ssr_87372__R1__L001.fastq.gz  \n",
      "  inflating: ssr_87372__R2__L001.fastq.gz  \n",
      "  inflating: ssr_87372__R2__L004.fastq.gz  \n",
      "\n",
      "Archive:  ssr_87301.zip\n",
      "  inflating: ssr_87301__R1__L001.fastq.gz  \n",
      "  inflating: ssr_87301__R1__L004.fastq.gz  \n",
      "  inflating: ssr_87301__R2__L004.fastq.gz  \n",
      "  inflating: ssr_87301__R2__L003.fastq.gz  \n",
      "  inflating: ssr_87301__R1__L003.fastq.gz  \n",
      "  inflating: ssr_87301__R2__L001.fastq.gz  \n",
      "  inflating: ssr_87301__R2__L002.fastq.gz  \n",
      "  inflating: ssr_87301__R1__L002.fastq.gz  \n",
      "\n",
      "3 archives were successfully processed.\n"
     ]
    }
   ],
   "source": [
    "!unzip \\*.zip\n",
    "!rm *.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip the fastq.gz files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!gunzip *.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Merging paired end reads\n",
    "\n",
    "You will notice there are eight fastq files for each sample. R1/R2 specifies whether or not the file has reverse reads or forward reads, and L001/L002/L003/L004 specifies what lane the sample was run on. Each sample was run four times in four different lanes, meaning L001-L004 should be very similar to each other and simply provide additional sequencing depth. We can concatenate the results from each lane to simplify analysis. \n",
    "\n",
    "Concatenate data from each lane into one R1 file and one R2 file. This must be done using bash rather than sh because bash [supports more complex string parsing.](http://stackoverflow.com/questions/5725296/difference-between-sh-and-bash) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for F in *L001.fastq; do\n",
    "    cat ${F:0:8}*__R1__* > ${F:0:8}_R1_.fastq\n",
    "done\n",
    "\n",
    "for F in *L001.fastq; do\n",
    "    cat ${F:0:8}*__R2__* > ${F:0:8}_R2_.fastq\n",
    "done\n",
    "\n",
    "#No longer a need for single files\n",
    "rm *__L*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will merge paired end reads using the qiime script [multiple_join_paired_ends.py](http://qiime.org/scripts/multiple_join_paired_ends.html). To view the options for any qiime script (and most scripts in general), use the -h option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: multiple_join_paired_ends.py [options] {-i/--input_dir INPUT_DIR -o/--output_dir OUTPUT_DIR}\r\n",
      "\r\n",
      "[] indicates optional input (order unimportant)\r\n",
      "{} indicates required input (order unimportant)\r\n",
      "\r\n",
      "This script runs join_paired_ends.py on data that are already demultiplexed\r\n",
      "(split up according to sample, with one sample per pair of files). The script\r\n",
      "supports the following types of input:\r\n",
      "\r\n",
      "- a directory containing many files, where each file is named on a per-sample\r\n",
      "  basis\r\n",
      "- a directory containing many directories, where each directory is named on a\r\n",
      "  per-sample basis\r\n",
      " \r\n",
      "The script assumes that the leading/trailing characters before/after the read\r\n",
      "number indicator (see --read1_indicator) are matched between forward and\r\n",
      "reverse reads. For example:\r\n",
      "\r\n",
      "- S0_L001_R1_001.fastq.gz and S0_L001_R2_001.fastq.gz would be matched up reads\r\n",
      "- S0_L002_R1_00X.fastq.gz and S0_L002_R2_00X.fastq.gz would be matched up reads\r\n",
      "\r\n",
      "If an optional --barcode_indicator file is used, it is searched for in the same\r\n",
      "manner that the paired files are searched for, so if the default \"_I1_\" is\r\n",
      "used, S0_L001_R1_001.fastq.gz and S0_L001_R2_001.fastq.gz would be matched up\r\n",
      "with S0_L001_I1_001.fastq.gz as the barcode indicator file.\r\n",
      "\r\n",
      "The output directory used for each call to join_paired_ends.py uses the base\r\n",
      "name of the input read 1 fastq file (a single directory would be problematic\r\n",
      "since the output names for join_paired_ends.py can be the same for different\r\n",
      "calls). Use the parameter --include_input_dir_path to also include the input\r\n",
      "directory name in the output directory path, which may be preferable in the\r\n",
      "case of an input folder of folders, and --remove_filepath_in_name can be used\r\n",
      "in this case to prevent the input read 1 fastq file base name from being used\r\n",
      "as part of the output directory name.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Example usage: \r\n",
      "Print help message and exit\r\n",
      " multiple_join_paired_ends.py -h\r\n",
      "\r\n",
      "Example 1: Process an input folder of paired-up files (by filename, with the default _R1_ and _R2_ containing the forward and reverse reads filenames, respectively). An optional parameters file is passed with -p. This file can specify an optional parameter for join_paired_ends.py, such as: join_paired_ends:pe_join_method SeqPrep\r\n",
      " multiple_join_paired_ends.py -i input_files -o output_folder -p qiime_parameters.txt\r\n",
      "\r\n",
      "Example 2: Process an input folder of folders (with the filenames having _forward_ and _reverse_ containing the forward and reverse read filenames, respectively). The individual folder names are included in the output folder names, but not the filenames. A matching barcode fastq file (indicated by _barcode_) is also included.\r\n",
      " multiple_join_paired_ends.py -i input_folders -o output_folder --read1_indicator '_forward_' --read2_indicator '_reverse_' --include_input_dir_path --remove_filepath_in_name -b --barcode_indicator '_barcode_'\r\n",
      "\r\n",
      "Example 3: To see what commands would be executed by the script without actually running them, use the following command\r\n",
      " multiple_join_paired_ends.py -i input_files -o output_folder -w\r\n",
      "\r\n",
      "Options:\r\n",
      "  --version             show program's version number and exit\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -p PARAMETER_FP, --parameter_fp=PARAMETER_FP\r\n",
      "                        path to the parameter file, which specifies changes to\r\n",
      "                        the default behavior of join_paired_ends.py. See\r\n",
      "                        http://www.qiime.org/documentation/file_formats.html\r\n",
      "                        #qiime-parameters [default: join_paired_ends.py\r\n",
      "                        defaults will be used]\r\n",
      "  --read1_indicator=READ1_INDICATOR\r\n",
      "                        Substring to search for to indicate read 1 [default:\r\n",
      "                        _R1_]\r\n",
      "  --read2_indicator=READ2_INDICATOR\r\n",
      "                        Substring to search for to indicate read 2 [default:\r\n",
      "                        _R2_]\r\n",
      "  -b, --match_barcodes  Enable searching for matching barcodes [default:\r\n",
      "                        False]\r\n",
      "  --barcode_indicator=BARCODE_INDICATOR\r\n",
      "                        Substring to search for to indicate barcode reads\r\n",
      "                        [default: _I1_]\r\n",
      "  --leading_text=LEADING_TEXT\r\n",
      "                        Leading text to add to each join_paired_ends.py\r\n",
      "                        command [default: no leading text added]\r\n",
      "  --trailing_text=TRAILING_TEXT\r\n",
      "                        Trailing text to add to each join_paired_ends.py\r\n",
      "                        command [default: no trailing text added]\r\n",
      "  --include_input_dir_path\r\n",
      "                        Include the input directory name in the output\r\n",
      "                        directory path. Useful in cases where the file names\r\n",
      "                        are repeated in input folders [default: False]\r\n",
      "  --remove_filepath_in_name\r\n",
      "                        Disable inclusion of the input filename in the output\r\n",
      "                        directory names. Must use --include_input_dir_path if\r\n",
      "                        this option is enabled [default: False]\r\n",
      "  -w, --print_only      Print the commands but don't call them -- useful for\r\n",
      "                        debugging [default: False]\r\n",
      "\r\n",
      "  REQUIRED options:\r\n",
      "    The following options must be provided under all circumstances.\r\n",
      "\r\n",
      "    -i INPUT_DIR, --input_dir=INPUT_DIR\r\n",
      "                        Input directory of directories, or directory of paired\r\n",
      "                        fastq files. [REQUIRED]\r\n",
      "    -o OUTPUT_DIR, --output_dir=OUTPUT_DIR\r\n",
      "                        Base output directory to write output folders\r\n",
      "                        [REQUIRED]\r\n"
     ]
    }
   ],
   "source": [
    "!multiple_join_paired_ends.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge our paired end reads, specify inputs, outputs, and the parameters. The parameters must be passed in a seperate file because multiple_join_paired_ends.py calls a different function, join_paired_ends.py, and we need to use parameters other than the default for join_paired_ends.py. To create a params file, we will write a quick file with python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('join_paired_end_reads_params.txt', 'w+') as f:\n",
    "                        f.write('join_paired_ends:perc_max_diff    99')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to join the paired ends. Don't forget to wait until the process is finishes ([\\*] is gone) to move on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!multiple_join_paired_ends.py -i ./ -o merged -p join_paired_endreads_params.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "At this point you have a file called \\*merged.fastq for each sample. Qiime requires one single fastq file with each read labelled with a sample ID to do future analyses. Time to merge again. \n",
    "\n",
    "This requires some work by hand. To begin, write out each file in alphabetical order, separated by commas but NO SPACES. You can use ls -l to see them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/ubiomeSamples/merged\r\n"
     ]
    }
   ],
   "source": [
    "chdir('merged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/ubiomeSamples/merged\n",
      "total 462360\n",
      "-rw-rw-r-- 1 ubuntu ubuntu      1886 Feb 26 22:13 log_20170226221319.txt\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  82620538 Feb 26 22:13 ssr_8730_R1_.merged.fastq\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 204009871 Feb 26 22:13 ssr_8737_R1_.merged.fastq\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 186813427 Feb 26 22:13 ssr_8797_R1_.merged.fastq\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, I might write: ssr_8730_R1_.merged.fastq,ssr_8737_R1_.merged.fastq,ssr_8797_R1_.merged.fastq\n",
    "\n",
    "Next, write down corresponding sample numbers, also separated by commas. MAKE SURE THEY CORRESPOND EXACTLY. For example:\n",
    "\n",
    "AB002,AB003,AB004\n",
    "\n",
    "The script we are going to use is called split_libraries_fastq.py. This script performs a number of functions, including demultiplexing of samples and quality filtering. Because fastq files provided by uBiome are already demultiplexed, we must pass this script the sample name associated with each file. For more information on qiime quality filtering, [check out this paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3531572/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#EDIT THIS CODE BEFORE YOU EVALUATE IT!\n",
    "!split_libraries_fastq.py -i [your list of fastq files] --sample_ids [your list of sample IDs] -o slout --barcode_type 'not-barcoded' -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!split_libraries_fastq.py -i ssr_8730_R1_.merged.fastq,ssr_8737_R1_.merged.fastq,ssr_8797_R1_.merged.fastq --sample_ids AB002,AB003,AB004 -o out --barcode_type 'not-barcoded' -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you (hopefully) have one file with all your mereged, cleaned, and filtered fastq reads in it. \n",
    "These reads should be identified with their sample numbers, for example:\n",
    "\n",
    "\\>AB002_0 NB501532:61:HGWJVAFXX:1:11101:9255:1102 1:N:0:CTACTCGA+CACATACG orig_bc=AAAAAAAAAAAA new_bc=AAAAAAAAAAAA bc_diffs=0\n",
    "CGTGTGCCAGCAGCCGCGGTAAGACGGGGGGGGCAAGTGTTCTTCGGAATGACTGGGCGTAAAGGGCACGTAGGCGGTGAATCGGGTTGAAAGTGAAAGTCGCCAAAAACTGGTGGAATGCTCTCGAAACCAATTCACTTGAGTGAGACAGTGGAATTTCGTGTGTAGGGGTGAAATCCGGAGATCTACGAAGGAAGGCCAAAAGCGAAGGCAGCTCTCTGGGTCCCCACCGACGCTGGAGTGCGAAAGCATGGGGAGCGAACGGGATTAGAAACCCCAGTAGTCCGGT\n",
    "\\>AB002_1 NB501532:61:HGWJVAFXX:1:11101:5822:1106 1:N:0:CTACTCGA+CACATACG orig_bc=AAAAAAAAAAAA new_bc=AAAAAAAAAAAA bc_diffs=0\n",
    "CGTGTGCCAGCAGCCGCGGTAATACAGAGGATGCAAGCGTTATCCGGAATGATTGGGCGTAAAGCGTCTGTAGGTGGCTTTTTAAGTCCGCCGTCAAATCCCAGGGCTCAACCCTGGACAGGCGGTGGAAACTACCAAGCTGGAGTACGGTCAGAGGGAATTTCCGGTGGAGCGGTGAAATGCGTAGAGATCGGAAAGAACACCAACGGCGAAAGCACTCTGCTGGGCCGACACTGACACTGAGAGACGAAAGCTAGGGGAGCGAATGGGATTAGAAACCCCAGTAGTCCGGA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##OTU Picking\n",
    "\n",
    "Next up, we'll be picking otu's! We will be using the script [pick_open_reference_otus.py](http://qiime.org/scripts/pick_open_reference_otus.html). We are specifying one important parameter, here, setting enable_rev_strand_match to True. This allows sequences to be considered a match if either their forward or reverse sequence hits the database. To set this parameter, we need to create a params file again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('uc_fast_params.txt', 'w+') as f:\n",
    "                        f.write('pick_otus:enable_rev_strand_match True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pick_open_reference_otus.py can take a looooong time depending on how big seqs.fna is. Around 3 hours for 15 merged samples, 1 hour for 3 samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pick_open_reference_otus.py -o otus/ -i slout/seqs.fna -p uc_fast_params.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESCRIPTION COPIED FROM [Illumina Overview Tutorial](http://nbviewer.jupyter.org/github/biocore/qiime/blob/1.9.1/examples/ipynb/illumina_overview_tutorial.ipynb)\n",
    "\n",
    "The primary output that we get from this command is the *OTU table*, or the number of times each operational taxonomic unit (OTU) is observed in each sample. QIIME uses the Genomics Standards Consortium Biological Observation Matrix standard (BIOM) format for representing OTU tables. You can find additional information on the BIOM format [here](http://www.biom-format.org), and information on converting these files to tab-separated text that can be viewed in spreadsheet programs [here](http://biom-format.org/documentation/biom_conversion.html). Several OTU tables are generated by this command. The one we typically want to work with is ``otus/otu_table_mc2_w_tax_no_pynast_failures.biom``. This has singleton OTUs (or OTUs with a total count of 1) removed, as well as OTUs whose representative (i.e., centroid) sequence couldn't be aligned with [PyNAST](http://bioinformatics.oxfordjournals.org/content/26/2/266.long). It also contains taxonomic assignments for each OTU as *observation metadata*.\n",
    "\n",
    "The open-reference OTU picking command also produces a phylogenetic tree where the tips are the OTUs. The file containing the tree is ``otus/rep_set.tre``, and is the file that should be used with ``otus/otu_table_mc2_w_tax_no_pynast_failures.biom`` in downstream phylogenetic diversity calculations. The tree is stored in the widely used [newick format](http://scikit-bio.org/docs/latest/generated/skbio.io.newick.html).\n",
    "\n",
    "To view the output of this command, call ``FileLink`` on the ``index.html`` file in the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='otus/index.html' target='_blank'>otus/index.html</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/ubiomeSamples/merged/otus/index.html"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('otus/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate some statistics on our OTUs using the biom program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples: 3\r\n",
      "Num observations: 13059\r\n",
      "Total count: 627933\r\n",
      "Table density (fraction of non-zero values): 0.378\r\n",
      "\r\n",
      "Counts/sample summary:\r\n",
      " Min: 103333.0\r\n",
      " Max: 279534.0\r\n",
      " Median: 245066.000\r\n",
      " Mean: 209311.000\r\n",
      " Std. dev.: 76247.462\r\n",
      " Sample Metadata Categories: None provided\r\n",
      " Observation Metadata Categories: taxonomy\r\n",
      "\r\n",
      "Counts/sample detail:\r\n",
      " AB002: 103333.0\r\n",
      " AB004: 245066.0\r\n",
      " AB003: 279534.0\r\n"
     ]
    }
   ],
   "source": [
    "!biom summarize-table -i otus/otu_table_mc2_w_tax_no_pynast_failures.biom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to pick what sequencing depth we would like to perform our rarefacation analysis on. Because different samples have different sequencing depths (i.e. numbers of reads) it would be wrong to assume that all had sequenced the diversity of the sample to the same extent. One common way to normalize sequencing depth across samples is to choose the sample with the lowest depth, and discard reads randomly in the remaining samples so that they all have the depth of the lowest sample. For a more detailed discussion on this, [see here](http://www.wernerlab.org/teaching/qiime/overview/e).\n",
    "\n",
    "Looking at the summary of your .biom file, note down the min number of reads in your samples (Min under Counts/sample summary). This is your sequencing depth. If you have one file that is far lower than all the others, it might make more sense to discard that sample from future analyses. You have to decide which is better: to discard one sample, or discard all the data from the other samples to acheive the same low sequencing depth as that one sample. \n",
    "\n",
    "##Core Diversity Analysis\n",
    "\n",
    "The script core_diversity_analyses.py will give us a first glance look at some important information about our samples. At this point, we need our mapping file. \n",
    "\n",
    "-e specifies the sequencing depth you will be using. The one I have is based on my data, replace it with something appropriate for yours! This step can also take a long time (~30 minutes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/ubiomeSamples/merged\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/local/bin/core_diversity_analyses.py\", line 202, in <module>\r\n",
      "    main()\r\n",
      "  File \"/usr/local/bin/core_diversity_analyses.py\", line 199, in main\r\n",
      "    status_update_callback=status_update_callback)\r\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/qiime/workflow/core_diversity_analyses.py\", line 252, in run_core_diversity_analyses\r\n",
      "    status_update_callback=status_update_callback)\r\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/qiime/workflow/downstream.py\", line 183, in run_beta_diversity_through_plots\r\n",
      "    close_logger_on_success=close_logger_on_success)\r\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/qiime/workflow/util.py\", line 122, in call_commands_serially\r\n",
      "    raise WorkflowError(msg)\r\n",
      "qiime.workflow.util.WorkflowError: \r\n",
      "\r\n",
      "*** ERROR RAISED DURING STEP: Make emperor plots, weighted_unifrac)\r\n",
      "Command run was:\r\n",
      " make_emperor.py -i cdout//bdiv_even103333//weighted_unifrac_pc.txt -o cdout//bdiv_even103333//weighted_unifrac_emperor_pcoa_plot/ -m ../map.tsv \r\n",
      "Command returned exit status: 2\r\n",
      "Stdout:\r\n",
      "\r\n",
      "Stderr\r\n",
      "Error in make_emperor.py: Due to the variation explained, Emperor could not plot at least 3 axes, check the input files to ensure that the percent explained is greater than 0.01 in at least three axes.\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!core_diversity_analyses.py -o cdout/ -i otus/otu_table_mc2_w_tax_no_pynast_failures.biom -m ../map.tsv -t otus/rep_set.tre -e 103333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/ubiomeSamples/merged\r\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
